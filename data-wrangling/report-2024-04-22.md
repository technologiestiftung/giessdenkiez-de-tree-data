# The new Baumkataster Report

Current state of investigation:

## Import and preparation

After importing downloading the new data from the wfs servise as geo.json using the script `tree_data/get_data_from_wfs.py`.

I created two tables to hold the data for the `s_wfs_baumbestand_an*[DATE]_.geo.json` and `s_wfs_baumbestand_[DATE]_.geo.json`.

```sql

CREATE TABLE "public"."temp_an_trees" (
    "gmlid" text,
    "baumid" text,
    "standortnr" text,
    "kennzeich" text,
    "namenr" text,
    "artdtsch" text,
    "artbot" text,
    "gattungdeutsch" text,
    "gattung" text,
    "art_gruppe" text,
    "pflanzjahr" int4,
    "standalter" text,
    "stammumfg" text,
    "bezirk" text,
    "eigentuemer" text,
    "kronedurch" text,
    "baumhoehe" text,
    geom geometry(Geometry,4326)
);

CREATE TABLE "public"."temp_trees" (
    "gmlid" text,
    "baumid" text,
    "standortnr" text,
    "kennzeich" text,
    "namenr" text,
    "artdtsch" text,
    "artbot" text,
    "gattungdeutsch" text,
    "gattung" text,
    "art_gruppe" text,
    "strname" text,
    "hausnr" text,
    "pflanzjahr" int4,
    "standalter" text,
    "stammumfg" text,
    "baumhoehe" text,
    "bezirk" text,
    "eigentuemer" text,
    "zusatz" text,
    "kronedurch" text,
    geom geometry(Geometry,4326)
);
```

I imported the data into the tables using the deno script `data-wrangling/main.ts` using the command ` deno run -A data-wrangling/main.ts --import-geojson`. Make sure that your environment variables are set correctly. See the sample.env file for the required variables. The sample.env contains a configuration that allows execution from within the docker container. The deno script was run on the local machine. Therefore the host option of `postgres` in the script is set to `localhost`. If you want you can also change `PGHOST` to `localhost`. and remove it from the script (around line 100).

```ts
const sql = postgres({
	host: "localhost",
});
```

Within the script there is also some logic that changes the coordinate reference system from the geo.json data to match the system used in GDK. Look for `// ETRS89 / UTM zone 33N`. This is the coordinate system from the incoming data. The script will transform the data to `EPSG:4326` which is the coordinate system used in GDK.

To import both datasets you need to change the following lines.

For the temp_trees table:

```ts
import geojson from `"../tree_data/data_files/s_wfs_baumbestand_2024-4-19.geo.json" with {type: "json"};
// (...)
const tableName = "temp_trees"
```

For the temp_an_trees table:

```ts
import geojson from `"../tree_data/data_files/s_wfs_baumbestand_an_2024-4-19.geo.json" with {type: "json"};
// (...)
const tableName = "temp_an_trees"
```

The script will import the data into the tables. The data is then available for further processing.

## Data Analysis

To be able to have the tables temp_trees and temp_an_trees in the same table I created a materilized view that combines the data from both tables. The view is called `combined_trees` and is created using the following query.

```sql
CREATE MATERIALIZED VIEW "public"."combined_trees" AS
SELECT
    "gmlid",
    "baumid",
    "standortnr",
    "kennzeich",
    "namenr",
    "artdtsch",
    "artbot",
    "gattungdeutsch",
    "gattung",
    "art_gruppe",
    "strname",
    "hausnr",
    "pflanzjahr",
    "standalter",
    "stammumfg",
    "baumhoehe",
    "bezirk",
    "eigentuemer",
    "zusatz",
    "kronedurch",
    "geom"
FROM
    "public"."temp_trees"
UNION ALL
SELECT
    "gmlid",
    "baumid",
    "standortnr",
    "kennzeich",
    "namenr",
    "artdtsch",
    "artbot",
    "gattungdeutsch",
    "gattung",
    "art_gruppe",
    NULL AS "strname",
    NULL AS "hausnr",
    "pflanzjahr",
    "standalter",
    "stammumfg",
    "baumhoehe",
    "bezirk",
    "eigentuemer",
    NULL AS "zusatz",
    "kronedurch",
    "geom"
FROM
    "public"."temp_an_trees";
```

The `NULL AS ...` is needed because some of the rows are missing on the `temp_an_trees` table.

For faster processing I created an index on the `gmlid` column.

```sql
CREATE INDEX idx_gmlid_on_combined_trees ON "public"."combined_trees" ("gmlid");
CREATE INDEX idx_gmlid_on_trees ON "public"."trees" ("gmlid");

```

What can we find out about the data?

### Quality of the data

```sql
-- how is the quality of the data in 2024
-- How many percent of the trees have no standalter
SELECT
	((
			SELECT
				COUNT(*)
			FROM
				combined_trees
			WHERE
				standalter IS NULL) * 100.0 / (
				SELECT
					COUNT(*)
				FROM
					combined_trees)) AS "combined_trees null standalter in Prozent";
-- Result: 18.1% have no standalter
```

```sql
-- how is the quality of the data in 2023
-- How many percent of the trees have no standalter
SELECT
	((
			SELECT
				COUNT(*)
			FROM
				trees
			WHERE
				standalter = 'undefined') * 100.0 / (
				SELECT
					COUNT(*)
				FROM
					trees)) AS "trees null standalter in Prozent";
-- Result: 17.4% have no standalter
```

### Location matching

What about the locations of the trees in the old and new dataset? Using the following query we can find out how many trees are in the same location in both datasets.

```sql
SELECT ct."gmlid"
FROM "public"."combined_trees" ct
LEFT JOIN "public"."trees" t ON ct."gmlid" = t."gmlid"
WHERE t."gmlid" IS NULL OR ST_DWithin(ct."geom"::geography, t."geom"::geography, 1) = FALSE;
```

This gives us a result of 78990 trees that are not in the same location in both datasets.

### Tree Counts

How many trees are in the old and new dataset?

```sql
SELECT COUNT(*) FROM "public"."trees";
-- Result: 839049
SELECT COUNT(*) FROM "public"."combined_trees";
-- Result: 885825
```

The new dataset has 46776 more trees than the old dataset.

#### Matching Trees

```sql
-- matching trees
SELECT COUNT(*)
FROM "public"."trees"
WHERE "gmlid" IN (
    SELECT "gmlid" FROM "public"."combined_trees"
);
-- or
SELECT
	COUNT(*)
FROM
	"public"."trees" t
	INNER JOIN "public"."combined_trees" ct ON t. "gmlid" = ct. "gmlid";

-- Result: 819483
```

#### Removed Trees

```sql
-- removed trees
SELECT COUNT(*)
FROM "public"."trees" t
LEFT JOIN "public"."combined_trees" c ON t."gmlid" = c."gmlid"
WHERE c."gmlid" IS NULL;
-- Result: 19566
```

```sql
-- Are some of the removed trees adopted?
select count(1) from trees_adopted where tree_id IN (SELECT
	t.id
FROM
	"public"."trees" t
	LEFT JOIN "public"."combined_trees" c ON t. "gmlid" = c. "gmlid"
WHERE
	c. "gmlid" IS NULL);
-- Result: 94
```

```sql
-- Have some of the removed trees been watered?
select count(1) from trees_watered where tree_id IN (SELECT
t.id
FROM
"public"."trees" t
LEFT JOIN "public"."combined_trees" c ON t. "gmlid" = c. "gmlid"
WHERE
c. "gmlid" IS NULL) GROUP by tree_id;
-- Result: 143 unique trees
```

#### New Trees

```sql
-- new trees
SELECT COUNT(*)
FROM "public"."combined_trees" c
LEFT JOIN "public"."trees" t ON c."gmlid" = t."gmlid"
WHERE t."gmlid" IS NULL;
-- Result: 66344
```

With these numbers I did some checkup calculations since the numbers did not add up.

```
old data set = 839049 Trees
new data set = 885825 Trees

removed trees = 19566 Trees
new trees = 66344 Trees

matching trees = 819483 Trees

diff = new data set - old data set => 46.776 Trees

new data set - matching trees => 66.342 Trees
```

## Qestions / Comments

The last line makes no sense to me. Why are there two more trees when I subtract the matching trees from the new data set? The result should be the same as the new trees query...

Also what about the number of trees that are not in the same location in both datasets? Is this a problem? How can we fix this?

## Suggestions

Since the data set and the process are under review here are some suggestions that could improve the data quality and the process:

- The columns standalter and pflanzjahr are both text columns but should be integers. !Note: Are we doing some parseInt() on them in the frontend?
- Someone thought that replacing the NULL values in pflanzjahr/standalter with the string value 'undefined' is a good idea. I think we should just keep the NULL values.
- Which of the columns are we using? Should we consolidate? We have lots of unused columns in the dataset just for the sake of having them. Reducing the number of columns could improve the performance of the database and the import process.
- There are some other columns that could be int instead of text. E.g. baumhoehe, stammumfng, kronendurch
- Drop the columns lat, lng and only use the geometry column for the locations (Warning harvester uses them)
- The data import does some unnecessary remapping from colmn names from e.g. gml_id to gmlid Why we just don't keep the original column names?
- The import script does some replacements on the pflanzjahr. All non numeric values are replaced by 0. I would suggest setting them to NULL
- Also all values greater than 9999 are replaced by 0. I would suggest setting them to NULL (or keep them as they are since someone created that dataset this way and the 9999 is just a magic number. Why not 8888 or 7777?)
